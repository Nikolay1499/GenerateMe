{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "#Flag if we need too create a new data array\n",
    "REBUILD_DATA = True\n",
    "\n",
    "#checking and setting the used device(either gpu or cpu)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A class for reading all the images from the data directory. The images are read as grayscale images and are resized to 64X64 with OpenCV and appended to a numpy array. The array is saved in the trainingData.npy and can be directly loaded instead of always recreating the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cats():\n",
    "    label = \"catData/data\"\n",
    "    \n",
    "    trainingData = []\n",
    "    catCount = 0\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def make_training_data(self):\n",
    "        for f in tqdm(os.listdir(self.label)):\n",
    "            try:\n",
    "                path = os.path.join(self.label, f)\n",
    "                img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img, (64, 64))\n",
    "                self.trainingData.append([np.array(img)])\n",
    "\n",
    "                self.catCount += 1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        np.random.shuffle(self.trainingData)\n",
    "        np.save(\"trainingData.npy\", self.trainingData)\n",
    "        print(\"CATS: \" + str(self.catCount))\n",
    "\n",
    "if REBUILD_DATA is True:   \n",
    "    obj = Cats()\n",
    "    obj.make_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = np.load(\"trainingData.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The two neural networks. In PyTorch a neural network could be a class. If implementing it as a class it inherits from nn.Module. The generator gets a z vector as input with a 100 features and generates an image. The descriminator has an image as input and outputs if the image is real or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(100, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 64 * 64)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return torch.tanh(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(64 * 64, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 1)\n",
    "    \n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = self.fc4(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating instances of the neural networks and moving them to the device(in my case the gpu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the optimisers and the loss function. The Discriminator has to decide if the image is real or not and its optimiser has to decrease the error probability. The Generator has to produce images that can fool the Discriminator and its optimiser has to increase the Discriminator's error probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "genOptimizer = optim.Adam(G.parameters(), lr = 0.0002)\n",
    "discOptimizer = optim.Adam(D.parameters(), lr = 0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spling the data - 90% for training and 10% for testing. Also the data is converted from [0, 255] to [-1, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([i[0] for i in trainingData]).view(-1, 1, 64, 64)\n",
    "x = x / 255.0\n",
    "x = (x - 0.5) / 0.5\n",
    "VAL_PCT = 0.1\n",
    "valSize = int(len(x) * VAL_PCT)\n",
    "print(valSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = x[:-valSize]\n",
    "testX = x[-valSize:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing one image with the correct PyTorch method and matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trainX[0].view(64, 64), cmap = \"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function for the Discriminator. It is first given a batch of real images each of which is rearanged in a linear way(64X64 image will 1X784). The loss is calculated from the real amages then a batch of fake images is generated and tested on the neural network. The combined loss is summed and backpropagation is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainDiscriminator(x):\n",
    "    D.zero_grad()\n",
    "\n",
    "    # train discriminator on real\n",
    "    xReal = x.view(-1, 64 * 64).to(device)\n",
    "    dOutput = D(xReal)\n",
    "    yReal = torch.ones(dOutput.size()[0], 1).to(device)\n",
    "    dRealLoss = criterion(dOutput, yReal)\n",
    "    dRealScore = dOutput\n",
    "\n",
    "    # train discriminator on facke\n",
    "    z = torch.randn(100, 100).to(device)\n",
    "    xFake = G(z)\n",
    "    yFake = torch.zeros(100, 1).to(device)\n",
    "\n",
    "    dOutput = D(xFake)\n",
    "    dFakeLoss = criterion(dOutput, yFake)\n",
    "    dFakeScore = dOutput\n",
    "\n",
    "    # gradient backprop & optimize ONLY D's parameters\n",
    "    discLoss = dRealLoss + dFakeLoss\n",
    "    discLoss.backward()\n",
    "    discOptimizer.step()\n",
    "        \n",
    "    return  discLoss.data.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function for the Generator. A batch of fake images is generated and tested on the Discriminator. The loss is calculated and backpropagation is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator(x):\n",
    "    G.zero_grad()\n",
    "    \n",
    "    z = torch.randn(100, 100).to(device)\n",
    "    y = torch.ones(100, 1).to(device)\n",
    "\n",
    "    genOutput = G(z)\n",
    "    discOutput = D(genOutput)\n",
    "    genLoss = criterion(discOutput, y)\n",
    "\n",
    "    # gradient backprop & optimize ONLY G's parameters\n",
    "    genLoss.backward()\n",
    "    genOptimizer.step()\n",
    "        \n",
    "    return genLoss.data.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training phase. TQDM is used to illustate the data loading better. On each EPOCH all the data is run through and the current statistics are printed. My dataset around 26000 images and it took 150 epochs to result in a relatively good image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 150\n",
    "BATCH = 100 \n",
    "for epoch in range(EPOCHS):\n",
    "    dLosses = []\n",
    "    gLosses = []\n",
    "    for i in tqdm(range(0, len(trainX), BATCH)):\n",
    "        batchX = trainX[i : i + BATCH]\n",
    "        dLosses.append(trainDiscriminator(batchX))\n",
    "        gLosses.append(trainGenerator(batchX))\n",
    "    print('[%d/%d]: loss disc: %.4f, loss gen: %.4f' % ((epoch + 1), EPOCHS, torch.mean(torch.FloatTensor(dLosses)), torch.mean(torch.FloatTensor(gLosses))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After training we can save the models and load them in another program just for testing purposes to simplify the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G.state_dict(), \"linearGanGeneratorModel.pt\")\n",
    "torch.save(D.state_dict(), \"linearGanDesciminatorModel.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to generate a new image with the generator and save it. Normalisation is used to return the image from [-1, 1] to [0, 255] which is used for grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(100, 100).to(device)\n",
    "    generated = G(z)\n",
    "    generated = generated.cpu()\n",
    "    plt.imshow(generated[0].view(64, 64), cmap = \"gray\")\n",
    "    plt.show()\n",
    "    save_image(generated[0].view(64, 64), \"sampleImage.png\", normalize = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
